{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c508d9c",
   "metadata": {},
   "source": [
    "## Extract Historical Stock Data from Yahoo Finance (openBB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32963f4",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fa693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:34:37.330558Z",
     "iopub.status.busy": "2025-06-06T01:34:37.330376Z",
     "iopub.status.idle": "2025-06-06T01:34:43.856549Z",
     "shell.execute_reply": "2025-06-06T01:34:43.856065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions to add: federal_reserve@1.4.3, yfinance@1.4.6\n",
      "Extensions to remove: federal_reserve@1.4.2, yfinance@1.4.3\n",
      "\n",
      "Building...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.abspath(os.path.join(os.getcwd(), '../..', 'py')) \n",
    "sys.path.append(current_dir)\n",
    "from fetch_price_history import fetch_price_history_openbb      \n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openbb import obb\n",
    "import polars as pl\n",
    "obb.user.credentials.fmp_api_key = os.getenv(\"FMP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec799a43",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bd232c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:34:43.858486Z",
     "iopub.status.busy": "2025-06-06T01:34:43.858290Z",
     "iopub.status.idle": "2025-06-06T01:34:43.863242Z",
     "shell.execute_reply": "2025-06-06T01:34:43.862759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range: 2015-06-08 to 2025-06-05\n",
      "Time span: 3650 days (10.00 years)\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Time Range adjustment\n",
    "end_date = (datetime.today() - BDay(1)).to_pydatetime()  # Last business day\n",
    "start_date = end_date - timedelta(days=10*365)  # 10 years of data\n",
    "\n",
    "# Convert datetime objects to Unix timestamps (seconds since Jan 1, 1970)\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "# Print the date range\n",
    "days_difference = (end_date - start_date).days\n",
    "print(f\"Date Range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Time span: {days_difference} days ({days_difference/365:.2f} years)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32027f8",
   "metadata": {},
   "source": [
    "### Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81532ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:34:43.864801Z",
     "iopub.status.busy": "2025-06-06T01:34:43.864627Z",
     "iopub.status.idle": "2025-06-06T01:35:22.836840Z",
     "shell.execute_reply": "2025-06-06T01:35:22.836229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_stock_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-06-04\n",
      "‚úÖ Found 500 tickers, ‚ùå Missing 3 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 3 missing tickers from 2015-05-19 to 2025-06-05\n",
      "Will update existing tickers from 2025-06-05 to 2025-06-05\n",
      "Using FMP batch processing for 503 tickers\n",
      "Fetching history for 3 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 3 tickers...\n",
      "Retrieved data for 3 of 3 missing tickers\n",
      "Updating 500 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "‚è≥ Round 1 complete with 200 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Updated data for 497 tickers\n",
      "‚ö†Ô∏è Column 'GEV' missing 206 values (40.8%) in recent data\n",
      "‚ö†Ô∏è Column 'LMT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LYB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MCHP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SOLV' missing 205 values (40.6%) in recent data\n",
      "‚ö†Ô∏è Column 'VLTO' missing 81 values (16.0%) in recent data\n",
      "üîÑ Fetching missing recent data for 6 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 6 tickers...\n",
      "‚úÖ Updated missing recent data for 6 tickers\n",
      "‚ö†Ô∏è Removing 3 columns with < 20.0% data or < 5 values:\n",
      "   GEV (299 values, 11.83%), SOLV (300 values, 11.87%), VLTO (424 values, 16.77%)\n",
      "üíæ Saved updated data to ../datasets/daily_stock_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_sp_500.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_stock_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_stock_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f7ba3",
   "metadata": {},
   "source": [
    "### Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ef97ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:35:22.838836Z",
     "iopub.status.busy": "2025-06-06T01:35:22.838471Z",
     "iopub.status.idle": "2025-06-06T01:36:30.116045Z",
     "shell.execute_reply": "2025-06-06T01:36:30.115454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_bond_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-06-04\n",
      "‚úÖ Found 101 tickers, ‚ùå Missing 46 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 46 missing tickers from 2015-05-19 to 2025-06-05\n",
      "Will update existing tickers from 2025-06-05 to 2025-06-05\n",
      "Using FMP batch processing for 147 tickers\n",
      "Fetching history for 46 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 46 tickers...\n",
      "Retrieved data for 27 of 46 missing tickers\n",
      "Updating 101 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚è≥ Round 1 complete with 1 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚ùå Max retries (1) reached. Skipping 1 tickers\n",
      "Updated data for 49 tickers\n",
      "‚ö†Ô∏è Column 'AGIH' missing 2 values (0.4%) in recent data\n",
      "‚ö†Ô∏è Column 'BMOPX' missing 505 values (100.0%) in recent data\n",
      "‚ö†Ô∏è Column 'CSHP' missing 284 values (56.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ELQD' missing 4 values (0.8%) in recent data\n",
      "‚ö†Ô∏è Column 'HYGI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBCA' missing 454 values (89.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDY' missing 15 values (3.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDZ' missing 247 values (48.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGA' missing 259 values (51.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGB' missing 455 values (90.1%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGL' missing 455 values (90.1%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHJ' missing 15 values (3.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIB' missing 73 values (14.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIC' missing 73 values (14.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBID' missing 73 values (14.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIE' missing 73 values (14.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIF' missing 77 values (15.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIG' missing 77 values (15.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIH' missing 77 values (15.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBII' missing 77 values (15.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIJ' missing 77 values (15.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIK' missing 247 values (48.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIL' missing 455 values (90.1%) in recent data\n",
      "‚ö†Ô∏è Column 'IBMQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTO' missing 19 values (3.8%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTP' missing 259 values (51.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTQ' missing 455 values (90.1%) in recent data\n",
      "‚ö†Ô∏è Column 'ICSH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ICVT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IEF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IEI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGBH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGEB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISHG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRC' missing 364 values (72.1%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRH' missing 365 values (72.3%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRI' missing 364 values (72.1%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRT' missing 363 values (71.9%) in recent data\n",
      "‚ö†Ô∏è Column 'LEMB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NYF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QLTA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SLQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'STIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TFLO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLTW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USIG' missing 1 values (0.2%) in recent data\n",
      "üîÑ Fetching missing recent data for 80 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 80 tickers...\n",
      "Rate limit reached. Identified 80 failed tickers\n",
      "‚è≥ Round 1 complete with 80 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 80 tickers...\n",
      "‚úÖ Updated missing recent data for 79 tickers\n",
      "‚ö†Ô∏è Removing 27 columns with < 20.0% data or < 5 values:\n",
      "   BMOPX (1 values, 0.04%), CSHP (221 values, 8.74%), IBCA (51 values, 2.02%), IBDY (490 values, 19.38%), IBDZ (258 values, 10.21%), IBGA (246 values, 9.73%), IBGB (50 values, 1.98%), IBGL (50 values, 1.98%), IBHJ (490 values, 19.38%), IBIB (432 values, 17.09%), ... and 17 more\n",
      "   Found 1 columns with fewer than 5 values!\n",
      "     - BMOPX: 1 values (0.040%)\n",
      "üíæ Saved updated data to ../datasets/daily_bond_quotes.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AGG</th>\n",
       "      <th>AGIH</th>\n",
       "      <th>AGRH</th>\n",
       "      <th>AGZ</th>\n",
       "      <th>BEMB</th>\n",
       "      <th>BGRN</th>\n",
       "      <th>BMOIX</th>\n",
       "      <th>BYLD</th>\n",
       "      <th>CEMB</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB</th>\n",
       "      <th>SUSB</th>\n",
       "      <th>SUSC</th>\n",
       "      <th>TFLO</th>\n",
       "      <th>TIP</th>\n",
       "      <th>TLH</th>\n",
       "      <th>TLT</th>\n",
       "      <th>TLTW</th>\n",
       "      <th>USHY</th>\n",
       "      <th>USIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>85.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.83</td>\n",
       "      <td>17.45</td>\n",
       "      <td>32.96</td>\n",
       "      <td>...</td>\n",
       "      <td>93.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.86</td>\n",
       "      <td>87.28</td>\n",
       "      <td>105.66</td>\n",
       "      <td>94.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>84.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.75</td>\n",
       "      <td>17.23</td>\n",
       "      <td>32.12</td>\n",
       "      <td>...</td>\n",
       "      <td>93.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.83</td>\n",
       "      <td>86.39</td>\n",
       "      <td>103.55</td>\n",
       "      <td>90.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>84.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17.36</td>\n",
       "      <td>32.32</td>\n",
       "      <td>...</td>\n",
       "      <td>93.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.74</td>\n",
       "      <td>86.85</td>\n",
       "      <td>106.14</td>\n",
       "      <td>95.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>84.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.79</td>\n",
       "      <td>17.27</td>\n",
       "      <td>31.66</td>\n",
       "      <td>...</td>\n",
       "      <td>93.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.72</td>\n",
       "      <td>86.03</td>\n",
       "      <td>105.57</td>\n",
       "      <td>94.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>85.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.84</td>\n",
       "      <td>17.21</td>\n",
       "      <td>30.80</td>\n",
       "      <td>...</td>\n",
       "      <td>93.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.78</td>\n",
       "      <td>85.58</td>\n",
       "      <td>107.51</td>\n",
       "      <td>96.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    AGG  AGIH  AGRH    AGZ  BEMB  BGRN  BMOIX   BYLD   CEMB  ...  \\\n",
       "0 2015-05-01  85.03   NaN   NaN  92.41   NaN   NaN   7.83  17.45  32.96  ...   \n",
       "1 2015-06-01  84.11   NaN   NaN  92.06   NaN   NaN   7.75  17.23  32.12  ...   \n",
       "2 2015-07-01  84.84   NaN   NaN  92.44   NaN   NaN   7.80  17.36  32.32  ...   \n",
       "3 2015-08-01  84.55   NaN   NaN  92.57   NaN   NaN   7.79  17.27  31.66  ...   \n",
       "4 2015-09-01  85.24   NaN   NaN  93.05   NaN   NaN   7.84  17.21  30.80  ...   \n",
       "\n",
       "     SUB  SUSB  SUSC   TFLO    TIP     TLH    TLT  TLTW  USHY   USIG  \n",
       "0  93.31   NaN   NaN  41.86  87.28  105.66  94.83   NaN   NaN  39.68  \n",
       "1  93.44   NaN   NaN  41.83  86.39  103.55  90.97   NaN   NaN  39.09  \n",
       "2  93.75   NaN   NaN  41.74  86.85  106.14  95.10   NaN   NaN  39.42  \n",
       "3  93.52   NaN   NaN  41.72  86.03  105.57  94.44   NaN   NaN  39.02  \n",
       "4  93.84   NaN   NaN  41.78  85.58  107.51  96.30   NaN   NaN  39.37  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers_file = '../tickers_bond.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_bond_quotes.csv'\n",
    "\n",
    "bonds_daily_df, failed_daily = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_bond_quotes.csv'\n",
    "\n",
    "bonds_monthly_prices = (bonds_daily_df.set_index(pd.to_datetime(bonds_daily_df.pop('Date')))\n",
    "      if 'Date' in bonds_daily_df.columns else bonds_daily_df.copy())\n",
    "bonds_monthly_prices.index = pd.to_datetime(bonds_monthly_prices.index)              \n",
    "bonds_monthly_prices = (bonds_monthly_prices.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .rename(columns={'index': 'Date'}))\n",
    "\n",
    "# Save to CSV\n",
    "bonds_monthly_prices.to_csv(monthly_output, index=False)\n",
    "\n",
    "display(bonds_monthly_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc1ac6",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62310d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:36:30.118107Z",
     "iopub.status.busy": "2025-06-06T01:36:30.117791Z",
     "iopub.status.idle": "2025-06-06T01:37:17.242395Z",
     "shell.execute_reply": "2025-06-06T01:37:17.241856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_benchmark_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-06-04\n",
      "‚úÖ Found 506 tickers, ‚ùå Missing 38 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 38 missing tickers from 2015-05-19 to 2025-06-05\n",
      "Will update existing tickers from 2025-06-05 to 2025-06-05\n",
      "Using FMP batch processing for 513 tickers\n",
      "Fetching history for 38 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 38 tickers...\n",
      "Retrieved data for 38 of 38 missing tickers\n",
      "Updating 475 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 75 tickers...\n",
      "Rate limit reached. Identified 75 failed tickers\n",
      "‚è≥ Round 1 complete with 275 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 75 tickers...\n",
      "Updated data for 456 tickers\n",
      "‚ö†Ô∏è Column 'ADME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'AIQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'BBP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'DGRW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'DSTL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'EDOG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ESGG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'EUSC' missing 4 values (0.8%) in recent data\n",
      "‚ö†Ô∏è Column 'FDD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FFIU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FIDU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FLRT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FMAT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FNCL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FTDS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FUTY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'FYC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'GAL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'GDXJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'GOAU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'GSY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'GVIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HFXI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HOMZ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HYS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HYUP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ICVT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IDHQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IDMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IDX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IEFA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IETC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IFRA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGEB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILCV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JDIV' missing 332 values (65.7%) in recent data\n",
      "‚ö†Ô∏è Column 'JPME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPSE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ONEO' missing 3 values (0.6%) in recent data\n",
      "‚ö†Ô∏è Column 'PFFR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PHYL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PPH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSCC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QARP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SSPY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VPU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WOMN' missing 2 values (0.4%) in recent data\n",
      "‚ö†Ô∏è Column 'XLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XRLV' missing 1 values (0.2%) in recent data\n",
      "üîÑ Fetching missing recent data for 54 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 54 tickers...\n",
      "‚úÖ Updated missing recent data for 25 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_benchmark_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_benchmark.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_benchmark_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_benchmark_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ad311",
   "metadata": {},
   "source": [
    "### Treasury Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d217effb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:37:17.244498Z",
     "iopub.status.busy": "2025-06-06T01:37:17.244044Z",
     "iopub.status.idle": "2025-06-06T01:37:47.911975Z",
     "shell.execute_reply": "2025-06-06T01:37:47.911373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_treasury_rates.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-06-04\n",
      "‚úÖ Found 4 tickers, ‚ùå Missing 0 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will update existing tickers from 2025-06-05 to 2025-06-05\n",
      "Using FMP batch processing for 4 tickers\n",
      "Updating 4 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 4 tickers...\n",
      "Rate limit reached. Adding entire batch to retry list\n",
      "‚è≥ Round 1 complete with 4 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 4 tickers...\n",
      "Rate limit reached. Adding entire batch to retry list\n",
      "‚ùå Max retries (1) reached. Skipping 4 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_treasury_rates.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_treasury.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_treasury_rates.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_treasury_rates.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c2018",
   "metadata": {},
   "source": [
    "### Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714d878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T01:37:47.913883Z",
     "iopub.status.busy": "2025-06-06T01:37:47.913500Z",
     "iopub.status.idle": "2025-06-06T01:37:47.916275Z",
     "shell.execute_reply": "2025-06-06T01:37:47.915839Z"
    }
   },
   "outputs": [],
   "source": [
    "sectors = [\n",
    "    'XLE',\n",
    "    'CLF',\n",
    "    'XLF',\n",
    "    'GDX'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
