{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c508d9c",
   "metadata": {},
   "source": [
    "## Extract Historical Stock Data from Yahoo Finance (openBB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32963f4",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fa693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:33:29.336471Z",
     "iopub.status.busy": "2025-05-29T01:33:29.336086Z",
     "iopub.status.idle": "2025-05-29T01:33:35.809545Z",
     "shell.execute_reply": "2025-05-29T01:33:35.809040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions to add: federal_reserve@1.4.3, yfinance@1.4.6\n",
      "Extensions to remove: federal_reserve@1.4.2, yfinance@1.4.3\n",
      "\n",
      "Building...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.abspath(os.path.join(os.getcwd(), '../..', 'py')) \n",
    "sys.path.append(current_dir)\n",
    "from fetch_price_history import fetch_price_history_openbb      \n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openbb import obb\n",
    "import polars as pl\n",
    "obb.user.credentials.fmp_api_key = os.getenv(\"FMP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec799a43",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bd232c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:33:35.811396Z",
     "iopub.status.busy": "2025-05-29T01:33:35.811215Z",
     "iopub.status.idle": "2025-05-29T01:33:35.816010Z",
     "shell.execute_reply": "2025-05-29T01:33:35.815553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range: 2015-05-31 to 2025-05-28\n",
      "Time span: 3650 days (10.00 years)\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Time Range adjustment\n",
    "end_date = (datetime.today() - BDay(1)).to_pydatetime()  # Last business day\n",
    "start_date = end_date - timedelta(days=10*365)  # 10 years of data\n",
    "\n",
    "# Convert datetime objects to Unix timestamps (seconds since Jan 1, 1970)\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "# Print the date range\n",
    "days_difference = (end_date - start_date).days\n",
    "print(f\"Date Range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Time span: {days_difference} days ({days_difference/365:.2f} years)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32027f8",
   "metadata": {},
   "source": [
    "### Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81532ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:33:35.817772Z",
     "iopub.status.busy": "2025-05-29T01:33:35.817433Z",
     "iopub.status.idle": "2025-05-29T01:34:15.629524Z",
     "shell.execute_reply": "2025-05-29T01:34:15.628917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_stock_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-27\n",
      "‚úÖ Found 500 tickers, ‚ùå Missing 3 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 3 missing tickers from 2015-05-19 to 2025-05-28\n",
      "Will update existing tickers from 2025-05-28 to 2025-05-28\n",
      "Using FMP batch processing for 503 tickers\n",
      "Fetching history for 3 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 3 tickers...\n",
      "Retrieved data for 3 of 3 missing tickers\n",
      "Updating 500 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "‚è≥ Round 1 complete with 200 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Updated data for 498 tickers\n",
      "‚ö†Ô∏è Column 'GEV' missing 211 values (41.9%) in recent data\n",
      "‚ö†Ô∏è Column 'LKQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LLY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SOLV' missing 210 values (41.7%) in recent data\n",
      "‚ö†Ô∏è Column 'VLTO' missing 86 values (17.1%) in recent data\n",
      "üîÑ Fetching missing recent data for 5 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 5 tickers...\n",
      "‚úÖ Updated missing recent data for 5 tickers\n",
      "‚ö†Ô∏è Removing 3 columns with < 20.0% data or < 5 values:\n",
      "   GEV (293 values, 11.62%), SOLV (294 values, 11.66%), VLTO (418 values, 16.57%)\n",
      "üíæ Saved updated data to ../datasets/daily_stock_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_sp_500.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_stock_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_stock_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f7ba3",
   "metadata": {},
   "source": [
    "### Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ef97ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:34:15.631624Z",
     "iopub.status.busy": "2025-05-29T01:34:15.631199Z",
     "iopub.status.idle": "2025-05-29T01:35:23.896112Z",
     "shell.execute_reply": "2025-05-29T01:35:23.895656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_bond_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-27\n",
      "‚úÖ Found 101 tickers, ‚ùå Missing 46 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 46 missing tickers from 2015-05-19 to 2025-05-28\n",
      "Will update existing tickers from 2025-05-28 to 2025-05-28\n",
      "Using FMP batch processing for 147 tickers\n",
      "Fetching history for 46 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 46 tickers...\n",
      "Retrieved data for 27 of 46 missing tickers\n",
      "Updating 101 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚è≥ Round 1 complete with 1 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚ùå Max retries (1) reached. Skipping 1 tickers\n",
      "Updated data for 49 tickers\n",
      "‚ö†Ô∏è Column 'AGIH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'BMOPX' missing 504 values (100.0%) in recent data\n",
      "‚ö†Ô∏è Column 'CMF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'CSHP' missing 288 values (57.1%) in recent data\n",
      "‚ö†Ô∏è Column 'ELQD' missing 2 values (0.4%) in recent data\n",
      "‚ö†Ô∏è Column 'GOVZ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'HYXU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IAGG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBCA' missing 459 values (91.1%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDY' missing 20 values (4.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDZ' missing 252 values (50.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGA' missing 264 values (52.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGB' missing 460 values (91.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGL' missing 460 values (91.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHJ' missing 20 values (4.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIB' missing 78 values (15.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIC' missing 78 values (15.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBID' missing 78 values (15.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIE' missing 78 values (15.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIF' missing 82 values (16.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIG' missing 82 values (16.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIH' missing 82 values (16.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBII' missing 82 values (16.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIJ' missing 82 values (16.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIK' missing 252 values (50.0%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIL' missing 460 values (91.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IBMN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBMR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTO' missing 24 values (4.8%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTP' missing 264 values (52.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTQ' missing 460 values (91.3%) in recent data\n",
      "‚ö†Ô∏è Column 'ICSH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGBH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGEB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRC' missing 369 values (73.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRH' missing 369 values (73.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRI' missing 369 values (73.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRT' missing 369 values (73.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QLTA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SLQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'STIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TFLO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLTW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USIG' missing 1 values (0.2%) in recent data\n",
      "üîÑ Fetching missing recent data for 79 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 79 tickers...\n",
      "Rate limit reached. Identified 79 failed tickers\n",
      "‚è≥ Round 1 complete with 79 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 79 tickers...\n",
      "‚úÖ Updated missing recent data for 78 tickers\n",
      "‚ö†Ô∏è Removing 27 columns with < 20.0% data or < 5 values:\n",
      "   BMOPX (1 values, 0.04%), CSHP (216 values, 8.56%), IBCA (45 values, 1.78%), IBDY (484 values, 19.19%), IBDZ (252 values, 9.99%), IBGA (240 values, 9.52%), IBGB (44 values, 1.74%), IBGL (44 values, 1.74%), IBHJ (484 values, 19.19%), IBIB (426 values, 16.89%), ... and 17 more\n",
      "   Found 1 columns with fewer than 5 values!\n",
      "     - BMOPX: 1 values (0.040%)\n",
      "üíæ Saved updated data to ../datasets/daily_bond_quotes.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AGG</th>\n",
       "      <th>AGIH</th>\n",
       "      <th>AGRH</th>\n",
       "      <th>AGZ</th>\n",
       "      <th>BEMB</th>\n",
       "      <th>BGRN</th>\n",
       "      <th>BMOIX</th>\n",
       "      <th>BYLD</th>\n",
       "      <th>CEMB</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB</th>\n",
       "      <th>SUSB</th>\n",
       "      <th>SUSC</th>\n",
       "      <th>TFLO</th>\n",
       "      <th>TIP</th>\n",
       "      <th>TLH</th>\n",
       "      <th>TLT</th>\n",
       "      <th>TLTW</th>\n",
       "      <th>USHY</th>\n",
       "      <th>USIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>85.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.83</td>\n",
       "      <td>17.45</td>\n",
       "      <td>32.96</td>\n",
       "      <td>...</td>\n",
       "      <td>93.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.86</td>\n",
       "      <td>87.28</td>\n",
       "      <td>105.66</td>\n",
       "      <td>94.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>84.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.75</td>\n",
       "      <td>17.23</td>\n",
       "      <td>32.12</td>\n",
       "      <td>...</td>\n",
       "      <td>93.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.83</td>\n",
       "      <td>86.39</td>\n",
       "      <td>103.55</td>\n",
       "      <td>90.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>84.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17.36</td>\n",
       "      <td>32.32</td>\n",
       "      <td>...</td>\n",
       "      <td>93.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.74</td>\n",
       "      <td>86.85</td>\n",
       "      <td>106.14</td>\n",
       "      <td>95.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>84.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.79</td>\n",
       "      <td>17.27</td>\n",
       "      <td>31.66</td>\n",
       "      <td>...</td>\n",
       "      <td>93.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.72</td>\n",
       "      <td>86.03</td>\n",
       "      <td>105.57</td>\n",
       "      <td>94.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>85.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.84</td>\n",
       "      <td>17.21</td>\n",
       "      <td>30.80</td>\n",
       "      <td>...</td>\n",
       "      <td>93.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.78</td>\n",
       "      <td>85.58</td>\n",
       "      <td>107.51</td>\n",
       "      <td>96.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    AGG  AGIH  AGRH    AGZ  BEMB  BGRN  BMOIX   BYLD   CEMB  ...  \\\n",
       "0 2015-05-01  85.03   NaN   NaN  92.41   NaN   NaN   7.83  17.45  32.96  ...   \n",
       "1 2015-06-01  84.11   NaN   NaN  92.06   NaN   NaN   7.75  17.23  32.12  ...   \n",
       "2 2015-07-01  84.84   NaN   NaN  92.44   NaN   NaN   7.80  17.36  32.32  ...   \n",
       "3 2015-08-01  84.55   NaN   NaN  92.57   NaN   NaN   7.79  17.27  31.66  ...   \n",
       "4 2015-09-01  85.24   NaN   NaN  93.05   NaN   NaN   7.84  17.21  30.80  ...   \n",
       "\n",
       "     SUB  SUSB  SUSC   TFLO    TIP     TLH    TLT  TLTW  USHY   USIG  \n",
       "0  93.31   NaN   NaN  41.86  87.28  105.66  94.83   NaN   NaN  39.68  \n",
       "1  93.44   NaN   NaN  41.83  86.39  103.55  90.97   NaN   NaN  39.09  \n",
       "2  93.75   NaN   NaN  41.74  86.85  106.14  95.10   NaN   NaN  39.42  \n",
       "3  93.52   NaN   NaN  41.72  86.03  105.57  94.44   NaN   NaN  39.02  \n",
       "4  93.84   NaN   NaN  41.78  85.58  107.51  96.30   NaN   NaN  39.37  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers_file = '../tickers_bond.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_bond_quotes.csv'\n",
    "\n",
    "bonds_daily_df, failed_daily = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_bond_quotes.csv'\n",
    "\n",
    "bonds_monthly_prices = (bonds_daily_df.set_index(pd.to_datetime(bonds_daily_df.pop('Date')))\n",
    "      if 'Date' in bonds_daily_df.columns else bonds_daily_df.copy())\n",
    "bonds_monthly_prices.index = pd.to_datetime(bonds_monthly_prices.index)              \n",
    "bonds_monthly_prices = (bonds_monthly_prices.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .rename(columns={'index': 'Date'}))\n",
    "\n",
    "# Save to CSV\n",
    "bonds_monthly_prices.to_csv(monthly_output, index=False)\n",
    "\n",
    "display(bonds_monthly_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc1ac6",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62310d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:35:23.897677Z",
     "iopub.status.busy": "2025-05-29T01:35:23.897503Z",
     "iopub.status.idle": "2025-05-29T01:36:43.604578Z",
     "shell.execute_reply": "2025-05-29T01:36:43.603955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_benchmark_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-27\n",
      "‚úÖ Found 506 tickers, ‚ùå Missing 0 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will update existing tickers from 2025-05-28 to 2025-05-28\n",
      "Using FMP batch processing for 505 tickers\n",
      "Updating 505 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 5 tickers...\n",
      "Rate limit reached. Identified 5 failed tickers\n",
      "‚è≥ Round 1 complete with 205 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 5 tickers...\n",
      "Rate limit reached. Identified 5 failed tickers\n",
      "‚ùå Max retries (1) reached. Skipping 205 tickers\n",
      "Updated data for 229 tickers\n",
      "‚ö†Ô∏è Column 'ADME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ESGG' missing 2 values (0.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IDOG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IETC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGBH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGRO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IJJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILCG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMCG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'INTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IPAC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IQLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISCF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ITA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JDIV' missing 338 values (67.1%) in recent data\n",
      "‚ö†Ô∏è Column 'JHMD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMBS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMOM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMST' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPSE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JQUA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JSMD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JVAL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KBWP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KCE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KIE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KORP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LKOR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LMBS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LRGF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LVHI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MAGA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MBSD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MDYV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFDX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFLX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MLPX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MMIT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MMTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MTUM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NACP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NANR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NULG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'OEF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ONEO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ONEQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ONEY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'OUSM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PAVE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PBUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PCEF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PFFA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PFFR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PFM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PHO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PHYL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PIZ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PJUL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PKB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PKW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'POCT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PPA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PPH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PRF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PRFZ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PRN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSCC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PSP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PULS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PWB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PXF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'PXH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QARP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QDEF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QDF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QEFA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QGRO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QINT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QLC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QLD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QMOM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QQQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QTUM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QUAL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QWLD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RAAX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RDIV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RDVY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'REGL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'REZ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RFEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RFV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RING' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RNEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ROAM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ROSC' missing 2 values (0.4%) in recent data\n",
      "‚ö†Ô∏è Column 'ROUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RSPG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RSPN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RSPR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RSPU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RTH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RWJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RWK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'RWL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SCHX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SDCI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SDVY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHRY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHYL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SIZE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SJNK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SKOR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SLQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SLX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SMH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SMIN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SMLF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SMLV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SMMU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SOXX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPGM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPGP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPHB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPHQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPLG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPTI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPTS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPVU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPXV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SPYV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SSPY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'STIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SYLD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TAXF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TBLU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TDTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'THD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLTD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TMFC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TOK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TUR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'UEVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'UITB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ULVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'URTH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USAI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USCI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USMC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USMF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USRT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'UTES' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VAMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VAW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VBR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VCIT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VCLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VCR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VCSH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VDC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VDE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VEA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VFH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VFMF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VFMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VFQY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VFVA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VGIT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VGSH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VGT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VHT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VLU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VONE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VONG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VOO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VOOG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VOOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VOT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VPC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VPU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VRIG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VRP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VTIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VTV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VUG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VUSE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VYM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'VYMI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WINC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WLDR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WOMN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WTMF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'WTV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XCEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XHB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XHS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XLY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XMHQ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XMMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XMVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XNTK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XRLV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XSMO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'XSVM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'YLD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'YLDE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'YYY' missing 1 values (0.2%) in recent data\n",
      "üîÑ Fetching missing recent data for 277 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 77 tickers...\n",
      "‚è≥ Round 1 complete with 200 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "‚úÖ Updated missing recent data for 201 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_benchmark_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_benchmark.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_benchmark_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_benchmark_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ad311",
   "metadata": {},
   "source": [
    "### Treasury Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d217effb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:36:43.606375Z",
     "iopub.status.busy": "2025-05-29T01:36:43.606190Z",
     "iopub.status.idle": "2025-05-29T01:36:43.958785Z",
     "shell.execute_reply": "2025-05-29T01:36:43.958235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_treasury_rates.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-27\n",
      "‚úÖ Found 4 tickers, ‚ùå Missing 0 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will update existing tickers from 2025-05-28 to 2025-05-28\n",
      "Using FMP batch processing for 4 tickers\n",
      "Updating 4 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 4 tickers...\n",
      "Updated data for 4 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_treasury_rates.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_treasury.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_treasury_rates.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_treasury_rates.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c2018",
   "metadata": {},
   "source": [
    "### Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714d878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:36:43.960413Z",
     "iopub.status.busy": "2025-05-29T01:36:43.960235Z",
     "iopub.status.idle": "2025-05-29T01:36:43.962754Z",
     "shell.execute_reply": "2025-05-29T01:36:43.962357Z"
    }
   },
   "outputs": [],
   "source": [
    "sectors = [\n",
    "    'XLE',\n",
    "    'CLF',\n",
    "    'XLF',\n",
    "    'GDX'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
