{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c508d9c",
   "metadata": {},
   "source": [
    "## Extract Historical Stock Data from Yahoo Finance (openBB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32963f4",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fa693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:32:45.966203Z",
     "iopub.status.busy": "2025-05-27T01:32:45.966009Z",
     "iopub.status.idle": "2025-05-27T01:32:52.387717Z",
     "shell.execute_reply": "2025-05-27T01:32:52.387158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions to add: federal_reserve@1.4.3, yfinance@1.4.6\n",
      "Extensions to remove: federal_reserve@1.4.2, yfinance@1.4.3\n",
      "\n",
      "Building...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.abspath(os.path.join(os.getcwd(), '../..', 'py')) \n",
    "sys.path.append(current_dir)\n",
    "from fetch_price_history import fetch_price_history_openbb      \n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openbb import obb\n",
    "import polars as pl\n",
    "obb.user.credentials.fmp_api_key = os.getenv(\"FMP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec799a43",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bd232c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:32:52.389512Z",
     "iopub.status.busy": "2025-05-27T01:32:52.389312Z",
     "iopub.status.idle": "2025-05-27T01:32:52.393900Z",
     "shell.execute_reply": "2025-05-27T01:32:52.393461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range: 2015-05-29 to 2025-05-26\n",
      "Time span: 3650 days (10.00 years)\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Time Range adjustment\n",
    "end_date = (datetime.today() - BDay(1)).to_pydatetime()  # Last business day\n",
    "start_date = end_date - timedelta(days=10*365)  # 10 years of data\n",
    "\n",
    "# Convert datetime objects to Unix timestamps (seconds since Jan 1, 1970)\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "# Print the date range\n",
    "days_difference = (end_date - start_date).days\n",
    "print(f\"Date Range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Time span: {days_difference} days ({days_difference/365:.2f} years)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32027f8",
   "metadata": {},
   "source": [
    "### Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81532ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:32:52.395466Z",
     "iopub.status.busy": "2025-05-27T01:32:52.395288Z",
     "iopub.status.idle": "2025-05-27T01:33:28.139423Z",
     "shell.execute_reply": "2025-05-27T01:33:28.138861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_stock_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-22\n",
      "‚úÖ Found 500 tickers, ‚ùå Missing 3 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 3 missing tickers from 2015-05-19 to 2025-05-26\n",
      "Will update existing tickers from 2025-05-23 to 2025-05-26\n",
      "Using FMP batch processing for 503 tickers\n",
      "Fetching history for 3 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 3 tickers...\n",
      "Retrieved data for 3 of 3 missing tickers\n",
      "Updating 500 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "‚è≥ Round 1 complete with 200 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Updated data for 498 tickers\n",
      "‚ö†Ô∏è Column 'GEV' missing 213 values (42.3%) in recent data\n",
      "‚ö†Ô∏è Column 'IEX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KIM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SOLV' missing 212 values (42.1%) in recent data\n",
      "‚ö†Ô∏è Column 'VLTO' missing 88 values (17.5%) in recent data\n",
      "üîÑ Fetching missing recent data for 5 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 5 tickers...\n",
      "‚úÖ Updated missing recent data for 5 tickers\n",
      "‚ö†Ô∏è Removing 3 columns with < 20.0% data or < 5 values:\n",
      "   GEV (291 values, 11.55%), SOLV (292 values, 11.59%), VLTO (416 values, 16.51%)\n",
      "üíæ Saved updated data to ../datasets/daily_stock_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_sp_500.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_stock_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_stock_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f7ba3",
   "metadata": {},
   "source": [
    "### Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ef97ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:33:28.141085Z",
     "iopub.status.busy": "2025-05-27T01:33:28.140899Z",
     "iopub.status.idle": "2025-05-27T01:34:34.207563Z",
     "shell.execute_reply": "2025-05-27T01:34:34.206933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_bond_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-22\n",
      "‚úÖ Found 101 tickers, ‚ùå Missing 46 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will fetch 46 missing tickers from 2015-05-19 to 2025-05-26\n",
      "Will update existing tickers from 2025-05-23 to 2025-05-26\n",
      "Using FMP batch processing for 147 tickers\n",
      "Fetching history for 46 missing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 46 tickers...\n",
      "Retrieved data for 27 of 46 missing tickers\n",
      "Updating 101 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚è≥ Round 1 complete with 1 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 1 tickers...\n",
      "Rate limit reached. Identified 1 failed tickers\n",
      "‚ùå Max retries (1) reached. Skipping 1 tickers\n",
      "Updated data for 50 tickers\n",
      "‚ö†Ô∏è Column 'AGIH' missing 4 values (0.8%) in recent data\n",
      "‚ö†Ô∏è Column 'BMOPX' missing 504 values (100.0%) in recent data\n",
      "‚ö†Ô∏è Column 'CSHP' missing 290 values (57.5%) in recent data\n",
      "‚ö†Ô∏è Column 'ELQD' missing 4 values (0.8%) in recent data\n",
      "‚ö†Ô∏è Column 'FIBR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IAGG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBCA' missing 461 values (91.5%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDY' missing 22 values (4.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBDZ' missing 254 values (50.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGA' missing 266 values (52.8%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGB' missing 462 values (91.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBGL' missing 462 values (91.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBHJ' missing 22 values (4.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIB' missing 80 values (15.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIC' missing 80 values (15.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBID' missing 80 values (15.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIE' missing 80 values (15.9%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIF' missing 84 values (16.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIG' missing 84 values (16.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIH' missing 84 values (16.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBII' missing 84 values (16.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIJ' missing 84 values (16.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIK' missing 254 values (50.4%) in recent data\n",
      "‚ö†Ô∏è Column 'IBIL' missing 462 values (91.7%) in recent data\n",
      "‚ö†Ô∏è Column 'IBMN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTO' missing 26 values (5.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTP' missing 266 values (52.8%) in recent data\n",
      "‚ö†Ô∏è Column 'IBTQ' missing 462 values (91.7%) in recent data\n",
      "‚ö†Ô∏è Column 'ICSH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ICVT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IEF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IEI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGBH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGEB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGLB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISHG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISTB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRC' missing 371 values (73.6%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRH' missing 371 values (73.6%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRI' missing 370 values (73.4%) in recent data\n",
      "‚ö†Ô∏è Column 'LDRT' missing 370 values (73.4%) in recent data\n",
      "‚ö†Ô∏è Column 'LEMB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NYF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'QLTA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SHYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SLQD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'STIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'SUSC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TFLO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TIP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'TLTW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USHY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'USIG' missing 1 values (0.2%) in recent data\n",
      "üîÑ Fetching missing recent data for 78 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 78 tickers...\n",
      "Rate limit reached. Identified 78 failed tickers\n",
      "‚è≥ Round 1 complete with 78 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 78 tickers...\n",
      "‚úÖ Updated missing recent data for 77 tickers\n",
      "‚ö†Ô∏è Removing 27 columns with < 20.0% data or < 5 values:\n",
      "   BMOPX (1 values, 0.04%), CSHP (214 values, 8.49%), IBCA (43 values, 1.71%), IBDY (482 values, 19.13%), IBDZ (250 values, 9.92%), IBGA (238 values, 9.44%), IBGB (42 values, 1.67%), IBGL (42 values, 1.67%), IBHJ (482 values, 19.13%), IBIB (424 values, 16.83%), ... and 17 more\n",
      "   Found 1 columns with fewer than 5 values!\n",
      "     - BMOPX: 1 values (0.040%)\n",
      "üíæ Saved updated data to ../datasets/daily_bond_quotes.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AGG</th>\n",
       "      <th>AGIH</th>\n",
       "      <th>AGRH</th>\n",
       "      <th>AGZ</th>\n",
       "      <th>BEMB</th>\n",
       "      <th>BGRN</th>\n",
       "      <th>BMOIX</th>\n",
       "      <th>BYLD</th>\n",
       "      <th>CEMB</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB</th>\n",
       "      <th>SUSB</th>\n",
       "      <th>SUSC</th>\n",
       "      <th>TFLO</th>\n",
       "      <th>TIP</th>\n",
       "      <th>TLH</th>\n",
       "      <th>TLT</th>\n",
       "      <th>TLTW</th>\n",
       "      <th>USHY</th>\n",
       "      <th>USIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>85.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.83</td>\n",
       "      <td>17.45</td>\n",
       "      <td>32.96</td>\n",
       "      <td>...</td>\n",
       "      <td>93.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.86</td>\n",
       "      <td>87.28</td>\n",
       "      <td>105.66</td>\n",
       "      <td>94.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>84.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.75</td>\n",
       "      <td>17.23</td>\n",
       "      <td>32.12</td>\n",
       "      <td>...</td>\n",
       "      <td>93.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.83</td>\n",
       "      <td>86.39</td>\n",
       "      <td>103.55</td>\n",
       "      <td>90.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>84.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17.36</td>\n",
       "      <td>32.32</td>\n",
       "      <td>...</td>\n",
       "      <td>93.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.74</td>\n",
       "      <td>86.85</td>\n",
       "      <td>106.14</td>\n",
       "      <td>95.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>84.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.79</td>\n",
       "      <td>17.27</td>\n",
       "      <td>31.66</td>\n",
       "      <td>...</td>\n",
       "      <td>93.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.72</td>\n",
       "      <td>86.03</td>\n",
       "      <td>105.57</td>\n",
       "      <td>94.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>85.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.84</td>\n",
       "      <td>17.21</td>\n",
       "      <td>30.80</td>\n",
       "      <td>...</td>\n",
       "      <td>93.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.78</td>\n",
       "      <td>85.58</td>\n",
       "      <td>107.51</td>\n",
       "      <td>96.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    AGG  AGIH  AGRH    AGZ  BEMB  BGRN  BMOIX   BYLD   CEMB  ...  \\\n",
       "0 2015-05-01  85.03   NaN   NaN  92.41   NaN   NaN   7.83  17.45  32.96  ...   \n",
       "1 2015-06-01  84.11   NaN   NaN  92.06   NaN   NaN   7.75  17.23  32.12  ...   \n",
       "2 2015-07-01  84.84   NaN   NaN  92.44   NaN   NaN   7.80  17.36  32.32  ...   \n",
       "3 2015-08-01  84.55   NaN   NaN  92.57   NaN   NaN   7.79  17.27  31.66  ...   \n",
       "4 2015-09-01  85.24   NaN   NaN  93.05   NaN   NaN   7.84  17.21  30.80  ...   \n",
       "\n",
       "     SUB  SUSB  SUSC   TFLO    TIP     TLH    TLT  TLTW  USHY   USIG  \n",
       "0  93.31   NaN   NaN  41.86  87.28  105.66  94.83   NaN   NaN  39.68  \n",
       "1  93.44   NaN   NaN  41.83  86.39  103.55  90.97   NaN   NaN  39.09  \n",
       "2  93.75   NaN   NaN  41.74  86.85  106.14  95.10   NaN   NaN  39.42  \n",
       "3  93.52   NaN   NaN  41.72  86.03  105.57  94.44   NaN   NaN  39.02  \n",
       "4  93.84   NaN   NaN  41.78  85.58  107.51  96.30   NaN   NaN  39.37  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers_file = '../tickers_bond.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_bond_quotes.csv'\n",
    "\n",
    "bonds_daily_df, failed_daily = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_bond_quotes.csv'\n",
    "\n",
    "bonds_monthly_prices = (bonds_daily_df.set_index(pd.to_datetime(bonds_daily_df.pop('Date')))\n",
    "      if 'Date' in bonds_daily_df.columns else bonds_daily_df.copy())\n",
    "bonds_monthly_prices.index = pd.to_datetime(bonds_monthly_prices.index)              \n",
    "bonds_monthly_prices = (bonds_monthly_prices.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .rename(columns={'index': 'Date'}))\n",
    "\n",
    "# Save to CSV\n",
    "bonds_monthly_prices.to_csv(monthly_output, index=False)\n",
    "\n",
    "display(bonds_monthly_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc1ac6",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62310d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:34:34.209422Z",
     "iopub.status.busy": "2025-05-27T01:34:34.209240Z",
     "iopub.status.idle": "2025-05-27T01:35:12.717562Z",
     "shell.execute_reply": "2025-05-27T01:35:12.716944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_benchmark_quotes.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-22\n",
      "‚úÖ Found 506 tickers, ‚ùå Missing 0 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will update existing tickers from 2025-05-23 to 2025-05-26\n",
      "Using FMP batch processing for 504 tickers\n",
      "Updating 504 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 100 tickers...\n",
      "Rate limit reached. Identified 100 failed tickers\n",
      "Fetching batch of 4 tickers...\n",
      "Rate limit reached. Identified 4 failed tickers\n",
      "‚è≥ Round 1 complete with 204 failed tickers\n",
      "Waiting 30 seconds before retrying...\n",
      "Processing attempt 2/2\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 100 tickers...\n",
      "Fetching batch of 4 tickers...\n",
      "Updated data for 427 tickers\n",
      "‚ö†Ô∏è Column 'ADME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IGHG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IJJ' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ILCV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMCG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMCV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IMTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'INTF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IOO' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IPAC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IPKW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IQDY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IQLT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ISCF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ITA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ITB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ITOT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IUSV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVLU' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IVW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IWY' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXN' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IXP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYG' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'IYW' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JDIV' missing 340 values (67.5%) in recent data\n",
      "‚ö†Ô∏è Column 'JHMD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMBS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMOM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMST' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JMUB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPIB' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPME' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JPSE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JQUA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JSMD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'JVAL' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KBWP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KCE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KIE' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'KORP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LGOV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LKOR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LMBS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LQDH' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LRGF' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'LVHI' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MAGA' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MBSD' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MDYV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MEAR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFDX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFEM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFLX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MFUS' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGC' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGK' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MGV' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MLPX' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MMIT' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MMTM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'MTUM' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NACP' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'NANR' missing 1 values (0.2%) in recent data\n",
      "‚ö†Ô∏è Column 'ONEO' missing 4 values (0.8%) in recent data\n",
      "‚ö†Ô∏è Column 'TOK' missing 2 values (0.4%) in recent data\n",
      "üîÑ Fetching missing recent data for 80 tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 80 tickers...\n",
      "‚úÖ Updated missing recent data for 80 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_benchmark_quotes.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_benchmark.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_benchmark_quotes.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_benchmark_quotes.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ad311",
   "metadata": {},
   "source": [
    "### Treasury Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d217effb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:35:12.719707Z",
     "iopub.status.busy": "2025-05-27T01:35:12.719240Z",
     "iopub.status.idle": "2025-05-27T01:35:12.789862Z",
     "shell.execute_reply": "2025-05-27T01:35:12.789324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading existing data from: ../datasets/daily_treasury_rates.csv\n",
      "üóì Existing data: 2015-05-19 to 2025-05-22\n",
      "‚úÖ Found 4 tickers, ‚ùå Missing 0 tickers\n",
      "‚è≥ Fetching data using provider: fmp...\n",
      "Will update existing tickers from 2025-05-23 to 2025-05-26\n",
      "Using FMP batch processing for 4 tickers\n",
      "Updating 4 existing tickers...\n",
      "Processing attempt 1/2\n",
      "Fetching batch of 4 tickers...\n",
      "Updated data for 4 tickers\n",
      "üíæ Saved updated data to ../datasets/daily_treasury_rates.csv\n"
     ]
    }
   ],
   "source": [
    "tickers_file = '../tickers_treasury.txt'\n",
    "with open(tickers_file, 'r') as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Replace '.' with '-' for Yahoo Finance compatibility\n",
    "tickers = [t.replace('.', '-') for t in tickers]\n",
    "tickers = list(dict.fromkeys(tickers))  # Remove duplicates\n",
    "\n",
    "###########################################################\n",
    "# DAILY DATA\n",
    "###########################################################\n",
    "\n",
    "daily_output = '../datasets/daily_treasury_rates.csv'\n",
    "\n",
    "df_daily, df_daily_failed = fetch_price_history_openbb(\n",
    "    tickers, \n",
    "    start_date, \n",
    "    end_date,\n",
    "    data_file=daily_output,\n",
    "    interval='1d',                 # options: ['1d', '1w', '1M']\n",
    "    provider='fmp',                # options: ['fmp', 'yfinance']\n",
    "    row_threshold_pct=0.05,        # Filter out rows with fewer than 5% of columns containing values\n",
    "    column_threshold=0.2,          # Filter out columns with less than 20% of values\n",
    "    validate_recent_data=True,     # Enable recent data validation\n",
    "    recent_data_percentage=0.2     # Check the last 20% of rows\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# MONTHLY DATA\n",
    "###########################################################\n",
    "\n",
    "monthly_output = '../datasets/monthly_treasury_rates.csv'\n",
    "\n",
    "df = (df_daily.set_index(pd.to_datetime(df_daily.pop('Date')))\n",
    "      if 'Date' in df_daily.columns else df_daily.copy())\n",
    "df.index = pd.to_datetime(df.index)              \n",
    "(df.resample('MS').last()\n",
    "   .reset_index()\n",
    "   .to_csv(monthly_output, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c2018",
   "metadata": {},
   "source": [
    "### Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0714d878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T01:35:12.791667Z",
     "iopub.status.busy": "2025-05-27T01:35:12.791318Z",
     "iopub.status.idle": "2025-05-27T01:35:12.793870Z",
     "shell.execute_reply": "2025-05-27T01:35:12.793440Z"
    }
   },
   "outputs": [],
   "source": [
    "sectors = [\n",
    "    'XLE',\n",
    "    'CLF',\n",
    "    'XLF',\n",
    "    'GDX'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
